In this paper, we propose a framework, called STOIC, for executing machine learning applications in hybrid cloud settings using the serverless architecture. STOIC integrates an edge controller, an edge cloud, and a public cloud with GPU acceleration. When the scheduler at the edge controller receives a batch of images from open field camera traps, it predicts the total response time for processing the batch based on batch size and historical log data. In the selector mode, STOIC schedules the task to the runtime with the least predicted latency. In the duplicator mode, STOIC co-schedules the task on the edge cloud and GPU runtime in the public cloud. If the latter is deployed and predicted to be faster, the edge cloud job is terminated. Otherwise, STOIC halts GPU runtime and completes the task on the edge cloud. This mode further optimizes the selection process by excluding the volatile deployment time.

We present the design principles, implementation details, the feedback control mechanism, and different modeling methodologies to address the variability in edge and public cloud deployments. Our empirical evaluation demonstrates STOIC can schedule tasks on local and remote deployments to achieve a speedup of 2.3x versus our baseline scenario. STOIC's success rate for prediction placement  ranges from 85\% to 97\% for the application and datasets that we study. 

As part of future work, we plan to investigate substituting RANSAC with Gradient Boosting Regression Trees (GBRT) to capture the non-linearity in the processing time due to heterogeneous hardware across deployment options (runtimes). We also plan to investigate model check-pointing in the duplicator mode to better utilize computational resource on edge cloud and to improve the performance of the STOIC system.